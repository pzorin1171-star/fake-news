from flask import Flask, render_template, request, jsonify
from style_analyzer import StyleAnalyzer
import json

app = Flask(__name__)
analyzer = StyleAnalyzer()

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
try:
    analyzer.load_or_train_model()
    print("‚úÖ –î–µ—Ç–µ–∫—Ç–æ—Ä —Ñ–µ–π–∫–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    print(f"üìä –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {analyzer.model_accuracy:.2%}")
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {e}")

@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å —Ñ–æ—Ä–º–æ–π –≤–≤–æ–¥–∞"""
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze_text():
    """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏ –≤–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    try:
        data = request.get_json()
        text = data.get('text', '').strip()
        
        if not text:
            return jsonify({'error': '–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞'})
        
        if len(text) < 20:
            return jsonify({'error': '–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π. –í–≤–µ–¥–∏—Ç–µ –Ω–µ –º–µ–Ω–µ–µ 20 —Å–∏–º–≤–æ–ª–æ–≤.'})
        
        if len(text) > 10000:
            return jsonify({'error': '–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π. –ú–∞–∫—Å–∏–º—É–º 10000 —Å–∏–º–≤–æ–ª–æ–≤.'})
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞
        features = analyzer.extract_features(text)
        prediction = analyzer.predict(features)
        highlighted_text = analyzer.highlight_text(text)
        credibility_assessment = analyzer.assess_credibility(features, text)
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        visualization_data = {
            'clickbait_score': round(features['clickbait_score'] * 100),
            'emotional_score': round(features['emotional_score'] * 100),
            'certainty_score': round(features['certainty_score'] * 100),
            'formality_score': round(features['formality_score'] * 100),
            'source_score': round(features['source_indicator_score'] * 100),
            'balance_score': round(features['balance_score'] * 100),
        }
        
        # –†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ –±–∞–ª–ª–∞ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        reliability_score = analyzer.calculate_reliability_score(features, prediction, text)
        
        # –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        explanations = analyzer.generate_explanations(features, text)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–µ–∫—Å—Ç—É
        text_stats = {
            'length': len(text),
            'sentences': features.get('sentence_count', 0),
            'words': features.get('word_count', 0),
            'avg_sentence_length': round(features.get('avg_words_per_sentence', 0), 1)
        }
        
        result = {
            'success': True,
            'reliability_score': reliability_score,
            'is_fake': prediction['is_fake'],
            'fake_probability': round(prediction['fake_probability'] * 100, 1),
            'raw_fake_probability': round(prediction.get('raw_probability', 0) * 100, 1),
            'highlighted_text': highlighted_text,
            'features': features,
            'visualization_data': visualization_data,
            'explanations': explanations,
            'clickbait_words': features.get('clickbait_words', []),
            'certainty_words': features.get('certainty_words', []),
            'credibility_assessment': credibility_assessment,
            'text_stats': text_stats,
            'model_confidence': round(analyzer.model_accuracy * 100, 1)
        }
        
        return jsonify(result)
        
    except Exception as e:
        app.logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")
        return jsonify({'error': f'–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}'})

@app.route('/features', methods=['GET'])
def get_feature_info():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    features_info = {
        'features': [
            {'name': '–ö–ª–∏–∫–±–µ–π—Ç', 'description': '–ù–∞–ª–∏—á–∏–µ —Å–ª–æ–≤, –ø—Ä–∏–≤–ª–µ–∫–∞—é—â–∏—Ö –≤–Ω–∏–º–∞–Ω–∏–µ'},
            {'name': '–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å', 'description': '–°–∏–ª–∞ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–∫—Ä–∞—Å–∫–∏ —Ç–µ–∫—Å—Ç–∞'},
            {'name': '–ö–∞—Ç–µ–≥–æ—Ä–∏—á–Ω–æ—Å—Ç—å', 'description': '–°—Ç–µ–ø–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è—Ö'},
            {'name': '–§–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å', 'description': '–û—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å —Å—Ç–∏–ª—è –∏–∑–ª–æ–∂–µ–Ω–∏—è'},
            {'name': '–ò—Å—Ç–æ—á–Ω–∏–∫–∏', 'description': '–£–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏'},
            {'name': '–ë–∞–ª–∞–Ω—Å', 'description': '–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∏–∑–ª–æ–∂–µ–Ω–∏—è'}
        ],
        'model_info': {
            'name': '–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥ (Gradient Boosting)',
            'features_count': 15,
            'samples_trained': 1000,
            'accuracy': round(analyzer.model_accuracy * 100, 1)
        }
    }
    return jsonify(features_info)

@app.route('/api/health', methods=['GET'])
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞"""
    return jsonify({
        'status': 'ok',
        'model_loaded': analyzer.model is not None,
        'model_accuracy': analyzer.model_accuracy if hasattr(analyzer, 'model_accuracy') else 0
    })

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
