# prepare_dataset.py - –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–∏
import pandas as pd
import numpy as np
import os
import sys

def create_dataset(fake_path='Fake.csv', true_path='True.csv', output_path='fake_news_dataset.csv'):
    """
    –°–æ–∑–¥–∞–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ —Ñ–∞–π–ª–æ–≤ Fake.csv –∏ True.csv
    
    Args:
        fake_path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ñ–µ–π–∫–æ–≤—ã–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏
        true_path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏  
        output_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    
    Returns:
        pd.DataFrame: –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
    """
    
    print("=" * 60)
    print("–ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–¢–ê–°–ï–¢–ê –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø ML –ú–û–î–ï–õ–ò")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    print("[1/6] –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")
    if not os.path.exists(fake_path):
        print(f"   ‚ùå –§–∞–π–ª —Å —Ñ–µ–π–∫–æ–≤—ã–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {fake_path}")
        print("   –°–∫–∞—á–∞–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç —Å Kaggle:")
        print("   https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset")
        print("   –ò –ø–æ–º–µ—Å—Ç–∏—Ç–µ —Ñ–∞–π–ª—ã Fake.csv –∏ True.csv –≤ –ø–∞–ø–∫—É —Å –ø—Ä–æ–µ–∫—Ç–æ–º")
        return None
    
    if not os.path.exists(true_path):
        print(f"   ‚ùå –§–∞–π–ª —Å –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {true_path}")
        return None
    
    print(f"   ‚úÖ –§–∞–π–ª —Ñ–µ–π–∫–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {fake_path}")
    print(f"   ‚úÖ –§–∞–π–ª –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {true_path}")
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        print("[2/6] –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        df_fake = pd.read_csv(fake_path, encoding='utf-8')
        df_true = pd.read_csv(true_path, encoding='utf-8')
        
        print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ñ–µ–π–∫–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {len(df_fake)} –∑–∞–ø–∏—Å–µ–π")
        print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {len(df_true)} –∑–∞–ø–∏—Å–µ–π")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
        print("[3/6] –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö...")
        print(f"   –ö–æ–ª–æ–Ω–∫–∏ –≤ Fake.csv: {list(df_fake.columns)}")
        print(f"   –ö–æ–ª–æ–Ω–∫–∏ –≤ True.csv: {list(df_true.columns)}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å —Ç–µ–∫—Å—Ç–æ–º (–≤ —ç—Ç–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –æ–±—ã—á–Ω–æ 'text')
        text_column = None
        for col in ['text', 'content', 'article', 'title']:
            if col in df_fake.columns and col in df_true.columns:
                text_column = col
                break
        
        if text_column is None:
            print("   ‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –æ–±—â–∞—è –∫–æ–ª–æ–Ω–∫–∞ —Å —Ç–µ–∫—Å—Ç–æ–º. –ò—â—É –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã...")
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –ø–æ–¥—Ö–æ–¥—è—â—É—é –∫–æ–ª–æ–Ω–∫—É
            for col in df_fake.columns:
                if col in df_true.columns:
                    text_column = col
                    print(f"   –ò—Å–ø–æ–ª—å–∑—É—é –∫–æ–ª–æ–Ω–∫—É: {text_column}")
                    break
        
        if text_column is None:
            print("   ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –æ–±—â–∞—è –∫–æ–ª–æ–Ω–∫–∞ –≤ –æ–±–æ–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö!")
            print("   –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ Fake.csv:", list(df_fake.columns))
            print("   –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ True.csv:", list(df_true.columns))
            return None
        
        print(f"   ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–ª–æ–Ω–∫–∞ —Å —Ç–µ–∫—Å—Ç–æ–º: '{text_column}'")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤
        print("[4/6] –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –∫–ª–∞—Å—Å–æ–≤...")
        df_fake['label'] = 1  # 1 = –§–µ–π–∫–æ–≤–∞—è –Ω–æ–≤–æ—Å—Ç—å
        df_true['label'] = 0  # 0 = –î–æ—Å—Ç–æ–≤–µ—Ä–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å
        
        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏—è
        if text_column != 'text':
            df_fake = df_fake.rename(columns={text_column: 'text'})
            df_true = df_true.rename(columns={text_column: 'text'})
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (—Ç–µ–∫—Å—Ç –∏ –º–µ—Ç–∫–∞)
        df_fake = df_fake[['text', 'label']]
        df_true = df_true[['text', 'label']]
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã
        print("[5/6] –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤...")
        df_combined = pd.concat([df_fake, df_true], ignore_index=True)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        print("   –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö...")
        initial_count = len(df_combined)
        
        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Ç–µ–∫—Å—Ç—ã
        df_combined = df_combined.dropna(subset=['text'])
        df_combined['text'] = df_combined['text'].astype(str).str.strip()
        df_combined = df_combined[df_combined['text'].str.len() > 10]
        
        cleaned_count = len(df_combined)
        removed_count = initial_count - cleaned_count
        
        if removed_count > 0:
            print(f"   –£–¥–∞–ª–µ–Ω–æ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {removed_count}")
        
        # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        df_combined = df_combined.sample(frac=1, random_state=42).reset_index(drop=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        print("[6/6] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
        df_combined.to_csv(output_path, index=False, encoding='utf-8')
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        print("\n" + "=" * 60)
        print("‚úÖ –î–ê–¢–ê–°–ï–¢ –£–°–ü–ï–®–ù–û –°–û–ó–î–ê–ù")
        print("=" * 60)
        print(f"–ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª: {output_path}")
        print(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(df_combined)}")
        print(f"–§–µ–π–∫–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π (label=1): {df_combined['label'].sum()}")
        print(f"–î–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π (label=0): {len(df_combined) - df_combined['label'].sum()}")
        
        # –í—ã–≤–æ–¥–∏–º –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        print("\nüìä –ü—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö:")
        print("-" * 40)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ 2 –ø—Ä–∏–º–µ—Ä–∞ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        for label_value, label_name in [(0, "–î–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–µ"), (1, "–§–µ–π–∫–æ–≤—ã–µ")]:
            print(f"\n{label_name} –Ω–æ–≤–æ—Å—Ç–∏ (label={label_value}):")
            examples = df_combined[df_combined['label'] == label_value].head(2)
            for i, (_, row) in enumerate(examples.iterrows()):
                text_preview = row['text'][:100] + "..." if len(row['text']) > 100 else row['text']
                print(f"  {i+1}. {text_preview}")
        
        print("\n" + "=" * 60)
        print("–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("1. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å: python train_model.py")
        print("2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ: python app.py")
        print("=" * 60)
        
        return df_combined
        
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞: {str(e)}")
        print("\n–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
        print("1. –§–∞–π–ª—ã CSV –∏–º–µ—é—Ç –¥—Ä—É–≥—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏–ª–∏ –∫–æ–¥–∏—Ä–æ–≤–∫—É")
        print("2. –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø–∞–º—è—Ç–∏")
        print("3. –ü—Ä–æ–±–ª–µ–º—ã —Å –ø—Ä–∞–≤–∞–º–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª–∞–º")
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ—à–∏–±–∫–µ
        import traceback
        print("\n–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:")
        traceback.print_exc()
        
        return None

def verify_dataset(dataset_path='fake_news_dataset.csv'):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–∑–¥–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
    
    Args:
        dataset_path (str): –ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    """
    if not os.path.exists(dataset_path):
        print(f"‚ùå –î–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {dataset_path}")
        return False
    
    try:
        df = pd.read_csv(dataset_path)
        print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {dataset_path}")
        print(f"   –ó–∞–ø–∏—Å–µ–π: {len(df)}")
        print(f"   –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
        
        if 'text' not in df.columns or 'label' not in df.columns:
            print("‚ùå –í –¥–∞—Ç–∞—Å–µ—Ç–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ 'text' –∏–ª–∏ 'label'")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤
        label_counts = df['label'].value_counts()
        print(f"\nüìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
        for label, count in label_counts.items():
            percentage = (count / len(df)) * 100
            label_name = "–§–µ–π–∫–æ–≤—ã–µ" if label == 1 else "–î–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–µ"
            print(f"   {label_name} (label={label}): {count} –∑–∞–ø–∏—Å–µ–π ({percentage:.1f}%)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–æ–≤
        df['text_length'] = df['text'].astype(str).apply(len)
        print(f"\nüìè –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–æ–≤:")
        print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {df['text_length'].mean():.0f} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {df['text_length'].min()} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {df['text_length'].max()} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        empty_texts = df['text'].isnull().sum()
        if empty_texts > 0:
            print(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ –ø—É—Å—Ç—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤: {empty_texts}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –¥–∞—Ç–∞—Å–µ—Ç–∞: {str(e)}")
        return False

def create_small_test_dataset(original_path='fake_news_dataset.csv', 
                             output_path='test_dataset.csv',
                             sample_size=1000):
    """
    –°–æ–∑–¥–∞–µ—Ç –Ω–µ–±–æ–ª—å—à–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    
    Args:
        original_path (str): –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É
        output_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        sample_size (int): –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    """
    if not os.path.exists(original_path):
        print(f"‚ùå –ò—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {original_path}")
        return None
    
    try:
        df = pd.read_csv(original_path)
        
        # –ë–µ—Ä–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –≤—ã–±–æ—Ä–∫—É –ø–æ –∫–ª–∞—Å—Å–∞–º
        sample_per_class = sample_size // 2
        df_fake = df[df['label'] == 1].sample(sample_per_class, random_state=42)
        df_true = df[df['label'] == 0].sample(sample_per_class, random_state=42)
        
        df_test = pd.concat([df_fake, df_true], ignore_index=True)
        df_test = df_test.sample(frac=1, random_state=42).reset_index(drop=True)
        
        df_test.to_csv(output_path, index=False, encoding='utf-8')
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {output_path}")
        print(f"   –†–∞–∑–º–µ—Ä: {len(df_test)} –∑–∞–ø–∏—Å–µ–π")
        print(f"   –§–µ–π–∫–æ–≤—ã–µ: {df_test['label'].sum()} –∑–∞–ø–∏—Å–µ–π")
        print(f"   –î–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–µ: {len(df_test) - df_test['label'].sum()} –∑–∞–ø–∏—Å–µ–π")
        
        return df_test
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {str(e)}")
        return None

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    import argparse
    parser = argparse.ArgumentParser(description='–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Ñ–µ–π–∫–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π')
    parser.add_argument('--fake', default='Fake.csv', help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ñ–µ–π–∫–æ–≤—ã–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏')
    parser.add_argument('--true', default='True.csv', help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏')
    parser.add_argument('--output', default='fake_news_dataset.csv', help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞')
    parser.add_argument('--test', action='store_true', help='–°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç')
    parser.add_argument('--verify', action='store_true', help='–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç')
    
    args = parser.parse_args()
    
    if args.verify:
        # –†–µ–∂–∏–º –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
        verify_dataset(args.output)
        return
    
    if args.test:
        # –†–µ–∂–∏–º —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        if not os.path.exists(args.output):
            print(f"‚ùå –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –æ—Å–Ω–æ–≤–Ω–æ–π –¥–∞—Ç–∞—Å–µ—Ç")
            print(f"   –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python prepare_dataset.py")
            return
        
        create_small_test_dataset(args.output, 'test_dataset.csv')
        return
    
    # –†–µ–∂–∏–º —Å–æ–∑–¥–∞–Ω–∏—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    dataset = create_dataset(args.fake, args.true, args.output)
    
    if dataset is not None:
        # –ü–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        print("\n" + "=" * 60)
        print("–ü–†–û–í–ï–†–ö–ê –°–û–ó–î–ê–ù–ù–û–ì–û –î–ê–¢–ê–°–ï–¢–ê")
        print("=" * 60)
        verify_dataset(args.output)

if __name__ == '__main__':
    main()
