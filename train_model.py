# train_model.py
import pandas as pd
import numpy as np
import pickle
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split

def main():
    print("=" * 60)
    print("–û–ë–£–ß–ï–ù–ò–ï –£–ü–†–û–©–ï–ù–ù–û–ô –ú–û–î–ï–õ–ò –î–õ–Ø RENDER")
    print("=" * 60)
    
    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
    dataset_path = 'fake_news_dataset.csv'
    if not os.path.exists(dataset_path):
        print(f"[–û–®–ò–ë–ö–ê] –§–∞–π–ª {dataset_path} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏–ª–∏ prepare_dataset.py")
        return
    
    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("[1/4] –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    try:
        df = pd.read_csv(dataset_path)
        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ 'text' –∏ 'label'
        texts = df['text'].astype(str).fillna('').tolist()
        labels = df['label'].astype(int).values
        print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(texts)}")
    except Exception as e:
        print(f"[–û–®–ò–ë–ö–ê] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç: {e}")
        return
    
    # 3. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    print("[2/4] –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")
    X_train, X_test, y_train, y_test = train_test_split(
        texts, labels, test_size=0.2, random_state=42, stratify=labels
    )
    print(f"   –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_train)} –∑–∞–ø–∏—Å–µ–π")
    print(f"   –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_test)} –∑–∞–ø–∏—Å–µ–π")
    
    # 4. –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print("[3/4] –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è + –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
    model_pipeline = Pipeline([
        ('tfidf', TfidfVectorizer(
            max_features=3000,      # –ë–µ—Ä–µ–º 3000 —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤ (–¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏)
            stop_words='english',   # –£–±–∏—Ä–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ (–¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ –Ω—É–∂–Ω–∞ —Å–≤–æ—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞)
            ngram_range=(1, 2)      # –ë–µ—Ä–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –∏ –ø–∞—Ä—ã —Å–ª–æ–≤
        )),
        ('clf', LogisticRegression(
            C=1.0,
            max_iter=1000,          # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∏—Ç–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
            random_state=42,
            class_weight='balanced' # –ë–∞–ª–∞–Ω—Å–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã
        ))
    ])
    
    # –û–±—É—á–µ–Ω–∏–µ
    model_pipeline.fit(X_train, y_train)
    
    # 5. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    print("[4/4] –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏...")
    train_score = model_pipeline.score(X_train, y_train)
    test_score = model_pipeline.score(X_test, y_test)
    
    print(f"   –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {train_score:.4f}")
    print(f"   –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {test_score:.4f}")
    
    # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    output_path = 'simple_model.pkl'
    with open(output_path, 'wb') as f:
        pickle.dump(model_pipeline, f)
    
    print("\n" + "=" * 60)
    print(f"‚úÖ –ú–û–î–ï–õ–¨ –£–°–ü–ï–®–ù–û –û–ë–£–ß–ï–ù–ê –ò –°–û–•–†–ê–ù–ï–ù–ê –í '{output_path}'")
    print("=" * 60)
    
    # –ù–µ–±–æ–ª—å—à–æ–π —Ç–µ—Å—Ç
    print("\nüß™ –¢–µ—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ:")
    test_samples = [
        "Breaking news: Scientists discover revolutionary new method",
        "SHOCKING: This one weird trick will make you rich overnight!"
    ]
    
    for sample in test_samples:
        prob = model_pipeline.predict_proba([sample])[0][1]
        label = model_pipeline.predict([sample])[0]
        verdict = "–§–ï–ô–ö" if label == 1 else "–î–û–°–¢–û–í–ï–†–ù–û"
        print(f"   '{sample[:50]}...' ‚Üí {verdict} (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {prob:.2%})")

if __name__ == '__main__':
    main()
